<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="description" content="Shuai Ma is a PhD student at HKUST">
    <link rel="stylesheet" href="./personal_webpage_files/bootstrap.min.css">
    <link rel="stylesheet" href="./personal_webpage_files/all.min.css">
    <base href=".">
    <title>Shuai Ma (马帅)</title>
    <style>
        body {
            margin-top: 20px;
            margin-bottom: 30px;
            font-family: sans-serif;
            font-weight: lighter;
        }

        a {
            color: black;
            border-bottom: 1px dotted black;
        }

        a:hover,
        a:active {
            color: #2774AE;
            text-decoration: none;
        }

        h1 a {
            color: #6B747C;
            border: none;
        }

        h2 {
            font-size: 1.5em;
            border-bottom: 2px solid;
        }

        h3 {
            font-size: 1.2em;
            color: #000000;
        }

        h4 {
            font-size: 1em;
            font-family: sans-serif;
            font-weight: lighter;
            color: #000000;
            margin-top: 10px;
            margin-bottom: 30px;
        }

        .strong {
            color: #2774AE;
        }

        @media (max-width: 767.98px) {
            header {
                text-align: center;
            }
        }

        ul.social-icons {
            font-size: 1rem;
            margin-top: 24px;
            margin-bottom: 0;
        }

        ul.social-icons li::before {
            content: '[';
        }

        ul.social-icons li::after {
            content: ']';
        }

        ul.social-icons li a {
            border: none;
        }

        img.portrait {
            max-width: 100%;
        }

        @media (max-width: 767.98px) {
            img.portrait {
                display: block;
                max-width: 500px;
                margin: auto;
            }
        }

        .annotation {
            margin-top: -0.5em;
            margin-bottom: 0.5em;
            font-size: 12px;
            line-height: 12px;
        }

        .taxonomy img {
            max-width: 100%;
        }

        div.research-project {
            font-size: 14px;
            margin-bottom: 1.5rem;
        }

        div.line-of-research {
            background-color: #F0F0F0;
        }

        div.research-project video {
            max-width: 100%;
            margin-bottom: 0.5rem;
        }

        div.research-project p {
            margin-bottom: 0.3rem;
        }

        .news {
            font-size: 15px;
            margin-bottom: 0px;
        }

        #news-more {
            display: none;
        }

        .award {
            font-size: 15px;
            margin-bottom: 0px;
        }

        #award-more {
            display: none;
        }

        .tweets {
            overflow: auto;
            -webkit-overflow-scrolling: touch;
        }

        .info {
            border-style: none;
            font-weight: bold;
            color: #999;
        }

        hr.dash {
            border-top: 1px dashed #bbbbbb;
            margin-bottom: 15px;
            margin-top: 15px;
        }

        .switch {
            position: relative;
            display: block;
            width: 32px;
            height: 18px;
            float: left;
			top: 3px;
        }

        .slider {
            position: absolute;
            cursor: pointer;
            top: 3px;
            right: 0;
            bottom: -3px;
            left: 0;
            background-color: #ccc;
            transition: 0.5s;
        }

        .slider:before {
            position: absolute;
            content: "";
            height: 12px;
            width: 12px;
            left: 3px;
            bottom: 3px;
            background-color: white;
            transition: 0.5s;
        }

        .active .slider {
            background-color: #DB522F;
        }

        .active .slider:before {
            transform: translateX(14px);
        }
		
		.slider.round {
		  border-radius: 34px;
		}

		.slider.round:before {
		  border-radius: 50%;
		}

        .filter-buttons {
            text-align: center;
            margin-bottom: 20px;
        }

        .filter-buttons button {
            background-color: #2774AE;
            color: white;
            border: none;
            padding: 10px 15px;
            margin: 5px;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s, box-shadow 0.3s;
        }

        .filter-buttons button:hover {
            background-color: #195f80;
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }



    </style>
	
<body data-new-gr-c-s-check-loaded="14.1050.0" data-gr-ext-installed="">
	
	<!-- Google Tag Manager (noscript) -->
	<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-PFGW5C3"
	height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
	<!-- End Google Tag Manager (noscript) -->
	
    <header class="container">
        <h1 class="float-md-left mb-0">
            <a href="https://shuaima.cc/">Shuai Ma (马帅)</a>
        </h1>
        <ul class="list-inline float-md-right social-icons">
            <!-- <li class="list-inline-item"><a href="./personal_webpage_files/cv.pdf">CV/Resume</a></li> -->
            <li class="list-inline-item"><a href="https://scholar.google.com/citations?hl=en&user=qajd8BYAAAAJ">Google
                    Scholar</a></li>
            <li class="list-inline-item"><a href="https://github.com/mashuaiwudi">Github</a></li>
            <li class="list-inline-item"><a href="mailto:shuai.ma@connect.ust.hk">Email</a></li>
            <li class="list-inline-item"><a href="https://twitter.com/shuaima_hci">Twitter</a></li>
        </ul>
        <div class="clearfix"></div>
        <hr>
    </header>




      
    <div class="container">
        <div class="row mb-3">
            <div class="col-xl-8 col-lg-8 col-md-8">
				
	            <!-- <p> <b><i><span style="color: #FF0000;">Update:</span> I am hosting internships for students at UCLA who have research interests in HCI. Please drop me an email if you are interested in working with me on building future human-computer interactive systems! </i></b> 
				 </p> -->
			
                <p>
					Hey, this is Shuai. I am a PhD candidate in HCI Lab at <a href="https://hkust.edu.hk/">Hong Kong University of Science and Technology (HKUST)</a>. I'm fortunate to be advised by <a href="https://www.cse.ust.hk/~mxj/">Prof. Xiaojuan Ma</a>. 
                    <!-- Previously, I was trained in HCI (my master's degree) from the HCI lab of Chinese Academy of Science, supervised by <a href="https://people.ucas.ac.cn/~fengt">Prof. Feng Tian</a>. I also luckily worked with <a href="https://lcs.ios.ac.cn/~xiangmin/">Prof. Xiangmin Fan (Chinese Academy of Science, China)</a>, <a href="https://www.dakuowang.com/">Prof. Dakuo Wang (Northeastern University, USA)</a>, <a href="https://mingyin.org/">Prof. Ming Yin (Purdue University, USA)</a>. -->
                    <br><br>My research goal is to design human-centered interactive systems that users can easily understand and use, appropriately rely on, and effectively collaborate with.
                    <ul>
                        
                        <li>In the method part, I have developed <b>computational models</b> to understand target users (e.g., modeling their preferences, and capabilities) allowing
                            the designed system to adapt to individual users to boost task performance and user experience. Specifically, I designed novel interaction methods to promote humans' appropriate reliance on algorithms' not always perfect suggestions.</li>
                        <br>
                        <li>In the application part, I leveraged theories from cognitive science and social science, and adopted a human‑centered design to develop
                            interactive systems to assist users in solving real‑world problems in various domains, including <b>Decision Making</b>, <b>Education & Learning</b>, 
                            <b>Work & Creation</b>, <b>Healthcare & Wellbeing</b>.</li>
                        
                    </ul>
                    
                    
                    <!--My research interest lies in Human-AI Interaction. Previously, I utilized advanced CV and NLP techniques to build interactive tools for users' daily activities (e.g., photo-taking, video-editing), Education (e.g., MOOC learning, online classes), and Healthcare (e.g., Parkinson’s disease detection, online health community support). Currently, I am focusing on fostering transparent communication in human-human interaction and human-AI interaction with human-centered approaches. Also, I am interested in human-centered explainable AI (HCXAI).-->

                </p>
				
                <!-- <p>
					I publish at ACM <a href="https://dl.acm.org/conference/chi">CHI</a>, <a href="https://dl.acm.org/conference/uist">UIST</a>, and <a href="https://dl.acm.org/journal/imwut"> IMWUT </a> and have received 2 Best Paper and 4 Honorable Mention Awards. Taxonomies of my completed research can be found below.
                </p> -->
			 
            </div>
            <div class="offset-xl-0 col-lg-4 col-md-3">
                <img src="./personal_webpage_files/Me.jpg" class="portrait" alt="a portrait of shuai ma">
            </div>
        </div>

        <!-- <div>
            <img src="./personal_webpage_files/research_chart.png" class="portrait">
        </div> -->
        <br>
        <div class="row">
            <!-- left column -->
            <div class="col-lg-8 mb-2">
                <h2>
                    Selected Publications <font style="font-size: 15px;">(Full publications can be viewed through Google Scholar)</font>
					<!--
                    <div class="float-right">
                        <small class="ml-2">by category</small>
                        <div class="switch sort-by-date">
                            <span class="slider round"></span>
                        </div>
                    </div>
					-->
                </h2>
                
                <div class="filter-buttons">
                    <button onclick="filterPublications('All')">All</button>
                    <button onclick="filterPublications('Decision Making')">Decision Making</button>
                    <button onclick="filterPublications('Education')">Education</button>
                    <button onclick="filterPublications('Wellbeing')">Wellbeing</button>
                    <button onclick="filterPublications('Work')">Work & Creation</button>
                    <!-- <button onclick="filterPublications('Human-AI Collaboration')">Human-AI Collaboration</button> -->
                </div>

                <div class="research-projects">
					
                <!-- <div class="alert alert-secondary">
                    <h3>Please refer to <a href="https://www.hilab.dev/">HiLab's webpage</a> for more recent work (after 01/01/2021)</h3>
                </div> -->

                
                <div class="row research-project" data-sort="2023" data-category = "Decision Making,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/calibration.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							"Are You Really Sure?'' Understanding the Effects of Human Self-Confidence Calibration in AI-Assisted Decision Making
                        </h6>
                        <p class="text-muted">
                            <b><u>Shuai Ma</u></b>, Xinru Wang, Ying Lei, Chuhan Shi, Ming Yin, Xiaojuan Ma. (CHI 2024)<br>
                            <a class="info", href="./personal_webpage_files/paper_pdf/self_confidence_calibration.pdf">[PDF]</a>
                            
                        </p>
                       
                        <p>
							This paper investigates human self-confidence calibration in AI-assisted decision-making, conducting three user studies to analyze its effect on human-AI collaboration. The research examines the impact of self-confidence on AI reliance and tests three calibration mechanisms. Findings indicate that proper self-confidence calibration improves rational behavior and appropriate reliance in human-AI teams, offering insights into enhancing collaboration efficiency.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>

                
                <div class="row research-project" data-sort="2023" data-category = "Decision Making,Education,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/AI4coursework.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students
                        </h6>
                        <p class="text-muted">
                            Chengbo Zheng, Kangyu Yuan, Bingcan Guo, Reza Hadi Mogavi, Zhenhui Peng, <b><u>Shuai Ma</u></b>, Xiaojuan Ma. (CHI 2024)<br>

                            <a class="info", href="./personal_webpage_files/paper_pdf/chartingFuture.pdf">[PDF]</a>
                        </p>
                       
                        <p>
							This study investigates using AI usage data for learning assessment in project-based education. Through workshops with college students, we explored how AI data can reflect students' skills and contributions. The findings highlight the potential and challenges of integrating AI data in educational assessments, informing the development of future educational tools for data analysis and presentation.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>

                <div class="row research-project" data-sort="2023" data-category = "Wellbeing,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/ICT.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							Unpacking ICT-supported Social Connections and Support of Late-life Migration: From the Lens of Social Convoys
                        </h6>
                        <p class="text-muted">
                            Ying Lei, <b><u>Shuai Ma</u></b>, Yuling Sun. (CHI 2024)<br>

                            <a class="info", href="./personal_webpage_files/paper_pdf/late_life_migration.pdf">[PDF]</a>
                        </p>
                       
                        <p>
							This paper explores the ICT-mediated social connections of late-life migrants, focusing on the dynamic changes in their social networks and the roles of ICT in these shifts. Utilizing the social convoy model, we examine the evolving support roles within migrants' networks, alongside the challenges and expectations related to ICT-supported social connections. Our findings offer in-depth insights into the social connections and support systems of late-life migrants, culminating in design implications for future ICT-based support systems for this demographic.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>
                
                <div class="row research-project" data-sort="2023" data-category = "Decision Making,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/human_ai_CL.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							Who Should I Trust: AI or Myself? Leveraging Human and AI Correctness Likelihood to Promote Appropriate Trust in AI-Assisted Decision-Making
                        </h6>
                        <p class="text-muted">
                            <b><u>Shuai Ma</u></b>, Ying Lei, Xinru Wang, Chengbo Zheng, Chuhan Shi, Ming Yin, Xiaojuan Ma. (CHI 2023)<br>

                            <a class="info", href="./personal_webpage_files/paper_pdf/human_AI_CL.pdf">[PDF]</a>
                            <a class="info", href="https://github.com/mashuaiwudi/mashuaiwudi.github.io/tree/master/HAIcollaboration">[Code]</a>
                            <a class="info", href="https://userstudy.link/HAIcollaboration/index.html">[Live Demo]</a>
                            <a class="info", href="https://www.youtube.com/watch?v=AWdUDaEqoSs">[Video]</a>
                        </p>
                       
                        <p>
							We proposed to promote humans' appropriate trust based on the correctness likelihood of both sides at a task-instance level. Results from a between-subjects experiment (N=293) showed that our CL exploitation strategies promoted more appropriate human trust in AI, compared with only using AI confidence.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>
                
                <div class="row research-project" data-sort="2023" data-category = "Decision Making,Work,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/retrolens.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							RetroLens: A Human-AI Collaborative System for Multi-step Retrosynthetic Route Planning
                        </h6>
                        <p class="text-muted">
                            Chuhan Shi, Yicheng Hu, Shenan Wang, <b><u>Shuai Ma</u></b>, Chengbo Zheng, Xiaojuan Ma, Qiong Luo. (CHI 2023)<br>

							<!-- <a class="info" href="https://vimeo.com/394833754">[Video]</a> -->
                            <!-- <a class="info" href="https://dl.acm.org/doi/abs/10.1145/3432232">[DOI]</a> -->
                            <a class="info", href="./personal_webpage_files/paper_pdf/RetroLens.pdf">[PDF]</a>
                        </p>
                       
                        <p>
							Targeting Multi-step Human-AI Collaboration task for chemists, we proposed a human-AI collaborative system, RetroLens, through a participatory design process. AI can contribute by two approaches: joint action and algorithm-inthe-loop.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>

                <div class="row research-project" data-sort="2023" data-category = "Decision Making,Education,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/aeser.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							Competent but Rigid: Identifying the Gap in Empowering AI to Participate Equally in Group Decision-Making
                        </h6>
                        <p class="text-muted">
                            Chengbo Zheng, Yuheng Wu, Chuhan Shi, <b><u>Shuai Ma</u></b>, Jiehui Luo, Xiaojuan Ma. (CHI 2023)<br>

							<!-- <a class="info" href="https://vimeo.com/394833754">[Video]</a> -->
                            <!-- <a class="info" href="https://dl.acm.org/doi/abs/10.1145/3432232">[DOI]</a> -->
                            <a class="info", href="./personal_webpage_files/paper_pdf/Competent but Rigid.pdf">[PDF]</a>
                        </p>
                       
                        <p>
							What will happen if AI participate equally in human group decision-making? We studied this problem in teacher-AI collaborative decision-making. We find that although the voice of AI is considered valuable, AI still plays a secondary role in the group because it cannot fully follow the dynamics of the discussion and make progressive contributions. Moreover, the divergent opinions
                            of our participants regarding an "equal AI" shed light on the possible future of human-AI relations.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>

                


                <div class="row research-project" data-sort="2022" data-category = "Education, Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/learning_engagement.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							Modeling Adaptive Expression of Robot Learning Engagement and Exploring its Effects on Human Teachers
                        </h6>
                        <p class="text-muted">
                            <b><u>Shuai Ma</u></b>, Mingfei Sun, Xiaojuan Ma. (TOCHI 2022)<br>
                            <a class="info", href="./personal_webpage_files/paper_pdf/LearningEngagement.pdf">[PDF]</a>
                            <a class="info", href="https://github.com/mashuaiwudi/mashuaiwudi.github.io">[Code]</a>
                            <a class="info", href="https://userstudy.link/">[Live Demo]</a>
                            <a class="info", href="https://www.youtube.com/watch?v=qm5YQl3Mj7Q">[Video]</a>
                        </p>
                       
                        <p>
							For human-robot teaching scenario, we propose an adaptive modeling and expression method to facilitate the transparent communication of robots' learning statuses during human demonstration.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>


					
                <div class="row research-project" data-sort="2022" data-category = "Education,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/glancee.png">
						   <!-- <source type="video/mp4" src="/research/MorphingCircuit/thumbnail.mp4">
						   <source type="video/webm" src="/research/MorphingCircuit/thumbnail.webm"> -->
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							Glancee: An Adaptable System for Instructors to Grasp Student Learning Status in Synchronous Online Classes
                        </h6>
                        <p class="text-muted">
                            <b><u>Shuai Ma</u></b>, Taichang Zhou, Fei Nie, Xiaojuan Ma. (CHI 2022)<br>

							<!-- <a class="info" href="https://vimeo.com/394833754">[Video]</a> -->
                            <!-- <a class="info" href="https://dl.acm.org/doi/abs/10.1145/3432232">[DOI]</a> -->
                            <a class="info", href="./personal_webpage_files/paper_pdf/glancee.pdf">[PDF]</a>
                            <a class="info", href="https://github.com/MiracleShuai/MiracleShuai.github.io">[Code]</a>
                            <a class="info", href="https://miracleshuai.github.io/index.html">[Live Demo]</a>
                            <a class="info", href="https://www.youtube.com/watch?v=QPMF5qOK6yI">[Video]</a>
                        </p>
                       
                        <p>
							Focusing on synchronous online classes (e.g., real-time Zoom-based classes), Glancee address instructors’ difficulty to observe students’ learning status due to students’ unwillingness to show their videos. Specifically, we mitigate the gap that lack of empirical investigation on instructors’ preferences and lack of exploration of designing adaptable systems to meet the needs of individual instructors. 
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>

                <div class="row research-project" data-sort="2022" data-category = "Wellbeing,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/cass.png">
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							CASS: Towards Building A Social-Support Chatbot for Online Health Community
                        </h6>
                        <p class="text-muted">
                            Liuping Wang, Dakuo Wang, Feng Tian, Zhenhui Peng, Xiangmin Fan, Zhan Zhang, <b><u>Shuai Ma</u></b>, Mo Yu, Xiaojuan Ma, Hongan Wang. (CSCW 2021)<br>

                            <a class="info", href="./personal_webpage_files/paper_pdf/cass.pdf">[PDF]</a>
                        </p>
                       
                        <p>
							We investigated how chatbots can be designed to provide information and emotional support for pregnant women in an online health community. 
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>


                <div class="row research-project" data-sort="2019" data-category = "Work,Human-AI Collaboration,All">
                    <div class="col-md-4">
                       <video loop="" muted="" playsinline="" poster="./personal_webpage_files/paper_teaser/smarteye.png">
                       </video>
					   
                    </div>
                    <div class="col-md-8">
                        <h6>
							SmartEye: Assisting Instant Photo Taking via Integrating User Preference with Deep View Proposal Network
                        </h6>
                        <p class="text-muted">
                            <b><u>Shuai Ma</u></b>, Zijun Wei, Feng Tian, Xiangmin Fan, Jianming Zhang, Xiaohui Shen, Zhe Lin, Jin Huang, Radomir Mech, Dimitris Samaras, Hongan Wang. (CHI 2019)<br>
                            <a class="info", href="./personal_webpage_files/paper_pdf/SmartEye.pdf">[PDF]</a>
                        </p>
                       
                        <p>
							How to effectively personalize a general model? 
                            We proposed a user preference modeling method based on interactive machine learning and designed a confidence-based integration framework to personalize a deep neural network to cater to users' individual preferences in photo composition. 
                            Based on the proposed algorithm, we designed SmartEye, which can gradually learn users' preferences as the interaction goes on.
                        </p>
                    </div>
					
					<div class="col-md-12"> 
						<hr class="dash">
					</div>
                </div>



                


                

                



            </div>
            </div>
            <!-- /left column -->
            <!-- right column -->
            <div class="col-lg-4 mb-2">
				

                <h2>Latest News</h2>
                <ul class="news" style="font-size: 13px">
                    <!-- <li>2024-1-19 | Three papers got conditionally accepted by CHI 2024! Congrats to my co-authors.</li> -->
                    <li>2023-11-9 | Arrived in Zurich. Visiting ETH.</li>
                    <li>2023-4-24 | Reconnect at CHI! Hamburg.</li>
                    <li>2023-1-24 | Happy to be a student volunteer at CHI 2023! See U in Germany.</li>
                    <li>2023-1-20 | Start my AC work for CHI 2023 LBW.</li>
                    <li>2023-1-14 | Three papers got accepted by CHI 2023! Congrats to my co-authors.</li>	
                </ul>
                <ul class="news" id="news-more" style="font-size: 13px">
                    
                    <li>2022-8-5 | Our paper 'Modeling Adaptive Expression of Robot Learning Engagement' has been accepted by TOCHI!</li>
                    <li>2022-4-19 | I passed my PhD Qualifying Exam and became a PhD candidate! Thanks for my committee members' valuable feedback!</li>
                    <li>2022-3-10 | Happy to be a student volunteer at CHI 2022!</li>
                    <li>2022-2-10 | Our paper <i>Glancee</i> is conditionally accepted at CHI 2022.</li>
                </ul>
                <a id="toggle-more-news" href="#">More &gt;</a>
				<br/>
				<br/>
				
				
                <h2>Teaching</h2>
                <ul class="news" style="font-size: 13px">
                    <li>2023-2024 Spring COMP4461 - Human-Computer Interaction (TA, @HKUST)</li>
					<li>2021-2022 Fall COMP 1021 - Introduction to Computer Science (TA, @HKUST)</li>
					<li>2020-2021 Spring COMP 1021 - Introduction to Computer Science (TA, @HKUST)</li>
                    <li>2018-2019 Introduction to Natural User Interfaces (Lecturer, @Beijing Zhongguancun No.1 Primary School)</li>
                    <li>2018 Introduction to Natural User Interfaces (Lecturer, @Beijing Science and Innovation Open Day)</li>
                </ul>
				<br>
				
				
                <h2>Service</h2>
				
				<p style="font-size: 13px">
                    <b>Program Committee</b>: ACM FAccT '24, ACM CHI '24 LBW, ACM CHI '23 LBW<br>
					<b>Conference Review</b>: ACM CHI '24<sup> (1)</sup>, '23<sup> (2)</sup>, '22, '20, '19, CSCW '23, UIST '22, CHI EA '23, '22, WWW '21 <br>
					<b>Journal Review</b>: ACM TOCHI, ACM TiiS, CCF TOPCI <br>
                    <b>Volunteer</b>: CHI' 23<sup> (3)</sup>, CHI' 22<sup> (4)</sup>
                    <br>
                    (1) (2) <i class="fa-solid fa-medal"></i>received Special Recognition for Outstanding Reviews for CHI 2023, CHI 2024
                    <br>
                    (3) (4) <i class="fa-solid fa-medal"></i>received Student Volunteer Award for CHI 2022, CHI 2023
				</p>

                <h2>Awards</h2>
                <ul class="award" style="font-size: 13px">
                    <li>2023 HKUST PhD Overseas Research Award</li>
                    <li>2020 HKUST Redbird PhD Scholarship</li>
					<li>2019 CHI Honorable Mention Award (first author)</li>
					<li>2019 President Scholarship in Chinese Academy of Sciences (in Chinese, 中科院院长奖学金, 1% selected)</li>
					<li>2018 National Scholarship for Graduate (in Chinese, 研究生国家奖学金, 1% selected)</li>
                    <li>2018 <b>Winner</b> of Huawei Cup Free Software Programming Competition (Ranked 1st among 50+ teams)</li>
					<li>2017 Excellence Award for Science Creation Program of Chinese Academy of Sciences</li>
					<li>2017 Special Scholarship for Undergraduates (in Chinese, 本科生特奖, 0.1% selected)</li>
                    <li>2016 National Scholarship for Undergraduate (in Chinese, 本科生国家奖学金, 1% selected)</li>
                </ul>
				<br>
        </div>

    </div>

<footer>
    <div class="container">
		<small> © 2022 - 2024 All rights reserved. Webpage template from <a href="https://www.yangzhang.dev/">Yang Zhang</a></small>
        <!-- <div style="margin-top:20px;" class="col-lg-8 mb-8"><p class="annotation">[Research focus diagram inspired by professor <a href="https://people.eecs.berkeley.edu/~bjoern/">Bjoern Hartmann</a>]</p></div> -->
	</div>
        
</footer>





<script src="https://cdn.jsdelivr.net/npm/jquery@3.4/dist/jquery.min.js"></script>
<script src="https://kit.fontawesome.com/1b68509e26.js" crossorigin="anonymous"></script>
<script>

    $('#toggle-more-award').click(function () {
        $('#award-more').slideToggle(function() {
            // 在动画完成后检查可见性
            if ($('#award-more').is(':visible')) {
                $('#toggle-more-award').text('< Hide');
            } else {
                $('#toggle-more-award').text('More >');
            }
        });
        return false;
    });

    $('#toggle-more-news').click(function () {
        $('#news-more').slideToggle(function() {
            // 在动画完成后检查可见性
            if ($('#news-more').is(':visible')) {
                $('#toggle-more-news').text('< Hide');
            } else {
                $('#toggle-more-news').text('More >');
            }
        });
        return false;
    });



    document.querySelectorAll('.email-anchor').forEach(function(a) {
        a.href = 'mailto:' + ['shuai.ma', 'connect.ust.hk'].join('@');
    });



    function filterPublications(category) {
    // 获取所有出版物
    var publications = document.getElementsByClassName('research-project');

    // 循环遍历所有出版物
    for (var i = 0; i < publications.length; i++) {
        var publicationCategories = publications[i].getAttribute('data-category').split(',');

        if (category == 'all' || publicationCategories.includes(category)) {
            publications[i].style.display = ''; // 显示
        } else {
            publications[i].style.display = 'none'; // 隐藏
        }
    }
}



</script>
